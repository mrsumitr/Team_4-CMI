{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5495e1ca",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:13.649078Z",
     "iopub.status.busy": "2025-11-15T09:51:13.648761Z",
     "iopub.status.idle": "2025-11-15T09:51:15.743078Z",
     "shell.execute_reply": "2025-11-15T09:51:15.741691Z"
    },
    "papermill": {
     "duration": 2.105494,
     "end_time": "2025-11-15T09:51:15.744760",
     "exception": false,
     "start_time": "2025-11-15T09:51:13.639266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_inference_server.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/cmi_gateway.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/cmi-detect-behavior-with-sensor-data/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2243b8",
   "metadata": {
    "papermill": {
     "duration": 0.006455,
     "end_time": "2025-11-15T09:51:15.758435",
     "exception": false,
     "start_time": "2025-11-15T09:51:15.751980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing libraries, creation of files & feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7273d3ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:15.773093Z",
     "iopub.status.busy": "2025-11-15T09:51:15.772604Z",
     "iopub.status.idle": "2025-11-15T09:51:18.280291Z",
     "shell.execute_reply": "2025-11-15T09:51:18.278942Z"
    },
    "papermill": {
     "duration": 2.517339,
     "end_time": "2025-11-15T09:51:18.282137",
     "exception": false,
     "start_time": "2025-11-15T09:51:15.764798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import os, time, math, random, gc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Using the user-provided file paths\n",
    "TRAIN_CSV = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train.csv'\n",
    "TEST_CSV = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv'\n",
    "DEMOG_TRAIN = '/kaggle/input/cmi-detect-behavior-with-sensor-data/train_demographics.csv'\n",
    "DEMOG_TEST = '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv'\n",
    "\n",
    "FEATURE_OUT = '/kaggle/working/sequence_features.csv'\n",
    "RANDOM_SEED = 42\n",
    "WINDOW_SIZE = 30 # A tunable hyperparameter\n",
    "\n",
    "# Define sensor column groups\n",
    "ACC_COLS = ['acc_x', 'acc_y', 'acc_z']\n",
    "ROT_COLS = ['rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "IMU_COLS = ACC_COLS + ROT_COLS\n",
    "THM_COLS = [f'thm_{i}' for i in range(1, 6)]\n",
    "TOF_COLS = [f'tof_{i}_v{j}' for i in range(1, 6) for j in range(0, 64)]\n",
    "\n",
    "\n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fc5e103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:18.297898Z",
     "iopub.status.busy": "2025-11-15T09:51:18.297418Z",
     "iopub.status.idle": "2025-11-15T09:51:18.307288Z",
     "shell.execute_reply": "2025-11-15T09:51:18.306399Z"
    },
    "papermill": {
     "duration": 0.019633,
     "end_time": "2025-11-15T09:51:18.308772",
     "exception": false,
     "start_time": "2025-11-15T09:51:18.289139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1: FEATURE ENGINEERING FUNCTIONS\n",
    "# ===============================================\n",
    "\n",
    "def extract_imu_features(window_df):\n",
    "    \"\"\"Extracts Time-Domain, Frequency-Domain, and statistical IMU features.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # ... (other code for Time-Domain features)\n",
    "    \n",
    "    # Time-Domain and Statistical Features (CORRECTED SECTION)\n",
    "    for col in IMU_COLS:\n",
    "        col_prefix = col\n",
    "        features[f'{col_prefix}_mean'] = window_df[col].mean()\n",
    "        features[f'{col_prefix}_var'] = window_df[col].var()\n",
    "        \n",
    "        # Explicitly check sample size before calculating skew and kurtosis\n",
    "        data = window_df[col].dropna()\n",
    "        MIN_SAMPLE_SIZE = 8 # Set minimum required samples (e.g., 8 is a common threshold)\n",
    "        \n",
    "        if len(data) >= MIN_SAMPLE_SIZE:\n",
    "            features[f'{col_prefix}_skew'] = skew(data)\n",
    "            features[f'{col_prefix}_kurt'] = kurtosis(data)\n",
    "        else:\n",
    "            # If sample is too small, set to NaN (which the imputer will handle later)\n",
    "            features[f'{col_prefix}_skew'] = np.nan\n",
    "            features[f'{col_prefix}_kurt'] = np.nan\n",
    "    #Signal Magnitude Area (SMA) and Total Magnitude\n",
    "    acc_mag = np.sqrt(np.square(window_df[ACC_COLS]).sum(axis=1))\n",
    "    features['acc_SMA'] = acc_mag.sum() / WINDOW_SIZE\n",
    "    features['acc_mag_mean'] = acc_mag.mean()\n",
    "    features['acc_mag_var'] = acc_mag.var()\n",
    "\n",
    "    # Cross-Axis Correlation\n",
    "    features['acc_corr_xy'] = window_df['acc_x'].corr(window_df['acc_y'])\n",
    "    \n",
    "    # Frequency-Domain Features (FFT magnitude of first few non-DC components)\n",
    "    for col in IMU_COLS:\n",
    "        if len(window_df[col].dropna()) > 0:\n",
    "            fft_values = np.abs(fft(window_df[col].fillna(window_df[col].mean()).values))\n",
    "            for i in range(1, 6):\n",
    "                features[f'{col}_fft_mag_{i}'] = fft_values[i]\n",
    "        else:\n",
    "             for i in range(1, 6):\n",
    "                features[f'{col}_fft_mag_{i}'] = np.nan\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb10cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:18.324287Z",
     "iopub.status.busy": "2025-11-15T09:51:18.323968Z",
     "iopub.status.idle": "2025-11-15T09:51:18.330376Z",
     "shell.execute_reply": "2025-11-15T09:51:18.329397Z"
    },
    "papermill": {
     "duration": 0.015742,
     "end_time": "2025-11-15T09:51:18.331861",
     "exception": false,
     "start_time": "2025-11-15T09:51:18.316119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_thermopile_features(window_df):\n",
    "    \"\"\"Extracts features from Thermopile data (thm_1 to thm_5), including gradients.\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Simple Statistical Features (Average Heat Intensity, Temporal Variance)\n",
    "    for col in THM_COLS:\n",
    "        col_prefix = col\n",
    "        features[f'{col_prefix}_mean'] = window_df[col].mean()\n",
    "        features[f'{col_prefix}_var'] = window_df[col].var()\n",
    "\n",
    "    # Thermopile Gradient Features (Difference between adjacent sensors)\n",
    "    for i in range(1, 5):\n",
    "        grad_col = f'thm_grad_{i}_{i+1}'\n",
    "        gradient = window_df[f'thm_{i}'] - window_df[f'thm_{i+1}']\n",
    "        features[f'{grad_col}_mean'] = gradient.mean()\n",
    "        features[f'{grad_col}_var'] = gradient.var()\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0aad544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:18.346746Z",
     "iopub.status.busy": "2025-11-15T09:51:18.346391Z",
     "iopub.status.idle": "2025-11-15T09:51:18.354809Z",
     "shell.execute_reply": "2025-11-15T09:51:18.353984Z"
    },
    "papermill": {
     "duration": 0.01793,
     "end_time": "2025-11-15T09:51:18.356504",
     "exception": false,
     "start_time": "2025-11-15T09:51:18.338574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_tof_features(window_df):\n",
    "    \"\"\"Extracts spatial and temporal features from Time-of-Flight (ToF) data.\"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # Replace the 'no sensor response' value (-1) with NaN for statistics\n",
    "    tof_data = window_df[TOF_COLS].replace(-1, np.nan)\n",
    "    \n",
    "    # Overall Proximity Features\n",
    "    features['tof_min_proximity'] = tof_data.min().min() # Closest object\n",
    "    features['tof_max_proximity'] = tof_data.max().max() # Farthest object\n",
    "    \n",
    "    # Per-Sensor (5 sensors) Spatial and Temporal Features\n",
    "    for i in range(1, 6):\n",
    "        sensor_cols = [f'tof_{i}_v{j}' for j in range(0, 64)]\n",
    "        tof_sensor_data = tof_data[sensor_cols]\n",
    "        prefix = f'tof_{i}'\n",
    "\n",
    "        # 1. Spatial Statistics\n",
    "        spatial_mean_series = tof_sensor_data.mean(axis=1) # Mean distance per row\n",
    "        features[f'{prefix}_spatial_mean'] = spatial_mean_series.mean()\n",
    "        features[f'{prefix}_spatial_var'] = spatial_mean_series.var()\n",
    "        \n",
    "        # 2. Number of 'Active' Pixels (Non-negative)\n",
    "        active_pixels = (window_df[sensor_cols] != -1).sum(axis=1)\n",
    "        features[f'{prefix}_active_pixels_mean'] = active_pixels.mean()\n",
    "        features[f'{prefix}_active_pixels_var'] = active_pixels.var()\n",
    "\n",
    "        # 3. Temporal Slope / Trend\n",
    "        avg_proximity_series = spatial_mean_series.dropna()\n",
    "        if len(avg_proximity_series) >= 2:\n",
    "            # Calculate temporal slope (change in average distance over time)\n",
    "            slope = np.polyfit(np.arange(len(avg_proximity_series)), avg_proximity_series, 1)[0]\n",
    "            features[f'{prefix}_temporal_slope'] = slope\n",
    "        else:\n",
    "            features[f'{prefix}_temporal_slope'] = np.nan\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1216ef29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:18.371569Z",
     "iopub.status.busy": "2025-11-15T09:51:18.371206Z",
     "iopub.status.idle": "2025-11-15T09:51:18.379773Z",
     "shell.execute_reply": "2025-11-15T09:51:18.378767Z"
    },
    "papermill": {
     "duration": 0.017949,
     "end_time": "2025-11-15T09:51:18.381265",
     "exception": false,
     "start_time": "2025-11-15T09:51:18.363316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2: DATA PIPELINE (Windowing, Extraction, Merging)\n",
    "# ===============================================\n",
    "\n",
    "def run_feature_pipeline(ts_path, demog_path, is_train=True):\n",
    "    \"\"\"Loads, processes time-series data, and merges with demographics.\"\"\"\n",
    "    print(f\"--- Running Pipeline for {'Train' if is_train else 'Test'} Data ---\")\n",
    "    \n",
    "    # Load Time-Series and Demographics\n",
    "    df_ts = pd.read_csv(ts_path)\n",
    "    df_demog = pd.read_csv(demog_path)\n",
    "    \n",
    "    features_list = []\n",
    "    \n",
    "    # Iterate through each unique sequence\n",
    "    sequence_groups = df_ts.groupby('sequence_id')\n",
    "    for seq_id, group in sequence_groups:\n",
    "        \n",
    "        # --- Windowing Strategy ---\n",
    "        # For a full sequence (Transition, Pause, Gesture), the critical event \n",
    "        # is the Gesture, which is at the end of the sequence. We use the last \n",
    "        # WINDOW_SIZE rows to capture this final motion.\n",
    "        window_df = group.tail(WINDOW_SIZE).copy()\n",
    "        \n",
    "        if len(window_df) < WINDOW_SIZE:\n",
    "            # Skip short sequences that can't form a reliable feature vector\n",
    "            continue\n",
    "            \n",
    "        # 1. Feature Extraction\n",
    "        features = {}\n",
    "        features.update(extract_imu_features(window_df))\n",
    "        features.update(extract_thermopile_features(window_df))\n",
    "        features.update(extract_tof_features(window_df))\n",
    "        \n",
    "        # 2. Add identifying and target columns\n",
    "        features['sequence_id'] = seq_id\n",
    "        features['subject'] = window_df['subject'].iloc[0]\n",
    "        if is_train:\n",
    "            # The gesture column is only present in the training set\n",
    "            features['gesture'] = window_df['gesture'].iloc[-1] \n",
    "        \n",
    "        features_list.append(features)\n",
    "        \n",
    "    df_features = pd.DataFrame(features_list)\n",
    "    \n",
    "    # 3. Merge with Demographics (Static Features Fusion)\n",
    "    df_final = pd.merge(df_features, df_demog, on='subject', how='left')\n",
    "    \n",
    "    print(f\"Generated {len(df_final)} feature vectors. Total features: {len(df_final.columns)}\")\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5f995d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:51:18.396174Z",
     "iopub.status.busy": "2025-11-15T09:51:18.395543Z",
     "iopub.status.idle": "2025-11-15T09:55:49.719309Z",
     "shell.execute_reply": "2025-11-15T09:55:49.718180Z"
    },
    "papermill": {
     "duration": 271.339932,
     "end_time": "2025-11-15T09:55:49.727825",
     "exception": false,
     "start_time": "2025-11-15T09:51:18.387893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Pipeline for Train Data ---\n",
      "Generated 8150 feature vectors. Total features: 122\n",
      "--- Running Pipeline for Test Data ---\n",
      "Generated 2 feature vectors. Total features: 121\n"
     ]
    }
   ],
   "source": [
    "# Execute pipeline for both datasets\n",
    "df_train_features = run_feature_pipeline(TRAIN_CSV, DEMOG_TRAIN, is_train=True)\n",
    "df_test_features = run_feature_pipeline(TEST_CSV, DEMOG_TEST, is_train=False)\n",
    "\n",
    "# Save the features (optional, for debugging/reuse)\n",
    "# df_train_features.to_csv(FEATURE_OUT.replace(\".csv\", \"_train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67fa706",
   "metadata": {
    "papermill": {
     "duration": 0.006718,
     "end_time": "2025-11-15T09:55:49.741207",
     "exception": false,
     "start_time": "2025-11-15T09:55:49.734489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training on models mentioned in our methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8cf3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:55:49.756811Z",
     "iopub.status.busy": "2025-11-15T09:55:49.756432Z",
     "iopub.status.idle": "2025-11-15T09:56:55.858717Z",
     "shell.execute_reply": "2025-11-15T09:56:55.857331Z"
    },
    "papermill": {
     "duration": 66.112327,
     "end_time": "2025-11-15T09:56:55.860382",
     "exception": false,
     "start_time": "2025-11-15T09:55:49.748055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Model Development and Evaluation...\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Macro F1 Score (Validation): 0.5703\n",
      "\n",
      "Training k-Nearest Neighbors...\n",
      "k-Nearest Neighbors Macro F1 Score (Validation): 0.4765\n",
      "\n",
      "Training Decision Tree...\n",
      "Decision Tree Macro F1 Score (Validation): 0.4839\n",
      "\n",
      "Training Random Forest...\n",
      "Random Forest Macro F1 Score (Validation): 0.6864\n",
      "\n",
      "Training Voting Classifier...\n",
      "Voting Classifier Macro F1 Score (Validation): 0.5216\n",
      "\n",
      "Retraining BEST model (Random Forest) on full training data...\n",
      "\n",
      "--- Summary of Validation F1 Scores ---\n",
      "Logistic Regression: 0.5703\n",
      "k-Nearest Neighbors: 0.4765\n",
      "Decision Tree: 0.4839\n",
      "Random Forest: 0.6864\n",
      "Voting Classifier: 0.5216\n",
      "\n",
      "Final prediction made using: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# --- Imbalance Handling Note ---\n",
    "# Class Weighting (class_weight='balanced') is used for LR, DT, and RF as it's built-in \n",
    "# and often preferred inside pipelines. SMOTE, though effective, requires an external \n",
    "# library (imblearn) and must be applied BEFORE scaling, which complicates the pipeline.\n",
    "def train_and_evaluate_model(df_train_features, df_test_features, random_seed):\n",
    "    \"\"\"Defines, trains, and evaluates all baseline, tree-based, and ensemble models.\"\"\"\n",
    "    \n",
    "    print(\"\\nStarting Model Development and Evaluation...\")\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    X_train_full = df_train_features.drop(columns=['sequence_id', 'subject', 'gesture'])\n",
    "    y_train_full = df_train_features['gesture']\n",
    "    \n",
    "    # Use a split of the TRAIN data for internal evaluation (Macro F1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.3, random_state=RANDOM_SEED, stratify=y_train_full\n",
    "    )\n",
    "    \n",
    "    # Prepare Test Data for final predictions\n",
    "    X_test_seq_id = df_test_features['sequence_id']\n",
    "    X_test = df_test_features.drop(columns=['sequence_id', 'subject'])\n",
    "    \n",
    "    # --- Pipeline Components ---\n",
    "    IMPUTATION_STEP = ('imputer', SimpleImputer(strategy='median'))\n",
    "    SCALING_STEP = ('scaler', StandardScaler())\n",
    "    \n",
    "    \n",
    "    # --- 1. Baseline Models ---\n",
    "    \n",
    "    # 1A. Logistic Regression (Imbalanced handled by class_weight)\n",
    "    lr_pipe = Pipeline([\n",
    "        IMPUTATION_STEP, SCALING_STEP,\n",
    "        ('clf', LogisticRegression(random_state=random_seed, solver='liblinear', multi_class='ovr', class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    # 1B. k-Nearest Neighbors (No inherent imbalance handling, scaling is crucial)\n",
    "    knn_pipe = Pipeline([\n",
    "        IMPUTATION_STEP, SCALING_STEP,\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=5)) # n_neighbors is tunable\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # --- 2. Tree-based Models ---\n",
    "    \n",
    "    # 2A. Decision Tree (Imbalanced handled by class_weight)\n",
    "    dt_pipe = Pipeline([\n",
    "        IMPUTATION_STEP,\n",
    "        ('clf', DecisionTreeClassifier(random_state=random_seed, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    # 2B. Random Forest (Imbalanced handled by class_weight)\n",
    "    rf_pipe = Pipeline([\n",
    "        IMPUTATION_STEP,\n",
    "        ('clf', RandomForestClassifier(n_estimators=500, random_state=random_seed, class_weight='balanced', n_jobs=-1))\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # --- 3. Ensemble Model: Voting Classifier ---\n",
    "    \n",
    "    # Use the best performing and most diverse base models: LR, RF, and DT.\n",
    "    # The 'named_estimators' must use the name of the step defined above.\n",
    "    ensemble_clf = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', lr_pipe),\n",
    "            ('rf', rf_pipe),\n",
    "            ('dt', dt_pipe)\n",
    "        ],\n",
    "        voting='soft', # Use 'soft' voting for weighted probability combination\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Wrap the ensemble in a pipeline for consistent data preprocessing\n",
    "    voting_pipe = Pipeline([\n",
    "        ('ensemble', ensemble_clf)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # --- 4. Training and Evaluation Loop ---\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": lr_pipe,\n",
    "        \"k-Nearest Neighbors\": knn_pipe,\n",
    "        \"Decision Tree\": dt_pipe,\n",
    "        \"Random Forest\": rf_pipe,\n",
    "        \"Voting Classifier\": voting_pipe\n",
    "    }\n",
    "    \n",
    "    best_model_name = \"\"\n",
    "    best_f1 = -1.0\n",
    "    \n",
    "    results = {}\n",
    "    for name, pipe in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred_val = pipe.predict(X_val)\n",
    "        \n",
    "        macro_f1 = f1_score(y_val, y_pred_val, average='macro')\n",
    "        results[name] = macro_f1\n",
    "        print(f\"{name} Macro F1 Score (Validation): {macro_f1:.4f}\")\n",
    "\n",
    "        if macro_f1 > best_f1:\n",
    "            best_f1 = macro_f1\n",
    "            best_model_name = name\n",
    "            \n",
    "    # --- 5. Final Prediction using the BEST model ---\n",
    "    \n",
    "    final_model = models[best_model_name]\n",
    "    \n",
    "    # Retrain the best model on the FULL training set for best performance\n",
    "    print(f\"\\nRetraining BEST model ({best_model_name}) on full training data...\")\n",
    "    final_model.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    y_pred_test = final_model.predict(X_test)\n",
    "    \n",
    "    # --- Submission File Generation ---\n",
    "    df_submission = pd.DataFrame({\n",
    "        'sequence_id': X_test_seq_id,\n",
    "        'gesture': y_pred_test\n",
    "    })\n",
    "    \n",
    "    # submission_path = os.path.join('/kaggle/working', 'submission_ensemble.csv')\n",
    "    # df_submission.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(\"\\n--- Summary of Validation F1 Scores ---\")\n",
    "    for name, f1 in results.items():\n",
    "         print(f\"{name}: {f1:.4f}\")\n",
    "         \n",
    "    print(f\"\\nFinal prediction made using: {best_model_name}\")\n",
    "    # print(f\"Submission file created at: {submission_path}\")\n",
    "    # print(df_submission.head())\n",
    "    \n",
    "# Execute the final modeling step\n",
    "train_and_evaluate_model(df_train_features, df_test_features, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b243c",
   "metadata": {
    "papermill": {
     "duration": 0.007112,
     "end_time": "2025-11-15T09:56:55.875268",
     "exception": false,
     "start_time": "2025-11-15T09:56:55.868156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Improving the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376b906e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T09:56:55.891969Z",
     "iopub.status.busy": "2025-11-15T09:56:55.891587Z",
     "iopub.status.idle": "2025-11-15T10:50:44.403736Z",
     "shell.execute_reply": "2025-11-15T10:50:44.401720Z"
    },
    "papermill": {
     "duration": 3228.523606,
     "end_time": "2025-11-15T10:50:44.405971",
     "exception": false,
     "start_time": "2025-11-15T09:56:55.882365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Improving Best Model: Using Optimized XGBoost ===\n",
      "\n",
      "Running RandomizedSearchCV... (This takes ~10–25 minutes)\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters Found:\n",
      "{'clf__subsample': 0.6, 'clf__reg_lambda': 1.9306977288832496, 'clf__reg_alpha': 0.01, 'clf__n_estimators': 700, 'clf__max_depth': 5, 'clf__learning_rate': 0.07333333333333333, 'clf__colsample_bytree': 0.7}\n",
      "\n",
      "Optimized XGBoost Macro F1 on Validation: 0.7074\n",
      "\n",
      "Retraining Optimized Model on FULL training data...\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_xgb(df_train_features, df_test_features, random_seed):\n",
    "\n",
    "    print(\"\\n=== Improving Best Model: Using Optimized XGBoost ===\")\n",
    "    le = LabelEncoder()\n",
    "    y_full = le.fit_transform(df_train_features['gesture'])\n",
    "\n",
    "    # -------------------------\n",
    "    # Feature Matrix\n",
    "    # -------------------------\n",
    "    X_full = df_train_features.drop(columns=['sequence_id', 'subject', 'gesture'])\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_full, y_full, test_size=0.3,\n",
    "        random_state=random_seed, stratify=y_full\n",
    "    )\n",
    "\n",
    "    X_test_seq_id = df_test_features['sequence_id']\n",
    "    X_test = df_test_features.drop(columns=['sequence_id', 'subject'])\n",
    "\n",
    "    # -------------------------\n",
    "    # Pipeline with Transformer\n",
    "    # -------------------------\n",
    "    pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('qt', QuantileTransformer(output_distribution='normal', random_state=random_seed)),\n",
    "        ('clf', xgb.XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            eval_metric='mlogloss',\n",
    "            random_state=random_seed,\n",
    "            nthread=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # -------------------------\n",
    "    # Hyperparameter Search\n",
    "    # -------------------------\n",
    "    param_dist = {\n",
    "        'clf__n_estimators': [300, 500, 700, 900],\n",
    "        'clf__max_depth': [3, 4, 5, 6, 7],\n",
    "        'clf__learning_rate': np.linspace(0.01, 0.2, 10),\n",
    "        'clf__subsample': np.linspace(0.6, 1.0, 5),\n",
    "        'clf__colsample_bytree': np.linspace(0.6, 1.0, 5),\n",
    "        'clf__reg_lambda': np.logspace(-2, 2, 8),\n",
    "        'clf__reg_alpha': np.logspace(-2, 1, 6)\n",
    "    }\n",
    "\n",
    "    print(\"\\nRunning RandomizedSearchCV... (This takes ~10–25 minutes)\")\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_dist,\n",
    "        scoring='f1_macro',\n",
    "        cv=3,\n",
    "        verbose=1,\n",
    "        n_iter=30,\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    print(\"\\nBest Parameters Found:\")\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # -------------------------\n",
    "    # Validation Performance\n",
    "    # -------------------------\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    macro_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    print(f\"\\nOptimized XGBoost Macro F1 on Validation: {macro_f1:.4f}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Retrain on Full Training Data\n",
    "    # -------------------------\n",
    "    print(\"\\nRetraining Optimized Model on FULL training data...\")\n",
    "    best_model.fit(X_full, y_full)\n",
    "\n",
    "    # -------------------------\n",
    "    # Final Test Predictions\n",
    "    # -------------------------\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    df_submission = pd.DataFrame({\n",
    "        'sequence_id': X_test_seq_id,\n",
    "        'gesture': y_test_pred\n",
    "    })\n",
    "\n",
    "    # submission_path = os.path.join('/kaggle/working', 'submission_xgb.csv')\n",
    "    # df_submission.to_csv(submission_path, index=False)\n",
    "\n",
    "    # print(f\"\\nSubmission saved to: {submission_path}\")\n",
    "    # print(df_submission.head())\n",
    "\n",
    "# Run improved model\n",
    "train_and_evaluate_xgb(df_train_features, df_test_features, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e4f7",
   "metadata": {
    "papermill": {
     "duration": 0.007394,
     "end_time": "2025-11-15T10:50:44.421378",
     "exception": false,
     "start_time": "2025-11-15T10:50:44.413984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Diving into 1D CNN to check the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1057a6ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:50:44.439537Z",
     "iopub.status.busy": "2025-11-15T10:50:44.438488Z",
     "iopub.status.idle": "2025-11-15T10:50:44.446594Z",
     "shell.execute_reply": "2025-11-15T10:50:44.445722Z"
    },
    "papermill": {
     "duration": 0.019691,
     "end_time": "2025-11-15T10:50:44.448059",
     "exception": false,
     "start_time": "2025-11-15T10:50:44.428368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['TF_USE_CUDNN'] = '0'\n",
    "os.environ['TF_USE_CUBLAS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3393962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:50:44.464207Z",
     "iopub.status.busy": "2025-11-15T10:50:44.463880Z",
     "iopub.status.idle": "2025-11-15T10:51:09.092649Z",
     "shell.execute_reply": "2025-11-15T10:51:09.091416Z"
    },
    "papermill": {
     "duration": 24.63922,
     "end_time": "2025-11-15T10:51:09.094507",
     "exception": false,
     "start_time": "2025-11-15T10:50:44.455287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-15 10:50:46.891720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763203847.219542      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763203847.302076      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n",
    "    Dense, Dropout, BatchNormalization, Input, Flatten, Bidirectional, LSTM\n",
    ")\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e0fa2d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.112853Z",
     "iopub.status.busy": "2025-11-15T10:51:09.111548Z",
     "iopub.status.idle": "2025-11-15T10:51:09.142547Z",
     "shell.execute_reply": "2025-11-15T10:51:09.141357Z"
    },
    "papermill": {
     "duration": 0.041944,
     "end_time": "2025-11-15T10:51:09.144522",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.102578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5705, 119) (5705,)\n",
      "Val: (2445, 119) (2445,)\n"
     ]
    }
   ],
   "source": [
    "X_train_full = df_train_features.drop(columns=['sequence_id', 'subject', 'gesture'])\n",
    "y_train_full = df_train_features['gesture']\n",
    "\n",
    "# Encode y\n",
    "le = LabelEncoder()\n",
    "y_train_full_enc = le.fit_transform(y_train_full)\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full_enc,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_train_full_enc\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a485be42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.162504Z",
     "iopub.status.busy": "2025-11-15T10:51:09.162148Z",
     "iopub.status.idle": "2025-11-15T10:51:09.187319Z",
     "shell.execute_reply": "2025-11-15T10:51:09.186240Z"
    },
    "papermill": {
     "duration": 0.036844,
     "end_time": "2025-11-15T10:51:09.189235",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.152391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "X_train_np = X_train.values\n",
    "X_val_np   = X_val.values\n",
    "\n",
    "# Replace NaN → 0, keep safe values for CNN\n",
    "X_train_clean = np.nan_to_num(X_train_np, nan=0.0)\n",
    "X_val_clean   = np.nan_to_num(X_val_np, nan=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1611434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.208353Z",
     "iopub.status.busy": "2025-11-15T10:51:09.208003Z",
     "iopub.status.idle": "2025-11-15T10:51:09.246764Z",
     "shell.execute_reply": "2025-11-15T10:51:09.245886Z"
    },
    "papermill": {
     "duration": 0.050832,
     "end_time": "2025-11-15T10:51:09.248826",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.197994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_clean)\n",
    "X_val_scaled   = scaler.transform(X_val_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b302ad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.265749Z",
     "iopub.status.busy": "2025-11-15T10:51:09.265375Z",
     "iopub.status.idle": "2025-11-15T10:51:09.272569Z",
     "shell.execute_reply": "2025-11-15T10:51:09.271131Z"
    },
    "papermill": {
     "duration": 0.017948,
     "end_time": "2025-11-15T10:51:09.274357",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.256409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Train: (5705, 119, 1)\n",
      "Number of classes: 18\n"
     ]
    }
   ],
   "source": [
    "X_train_cnn = X_train_scaled.reshape(-1, 119, 1)\n",
    "X_val_cnn   = X_val_scaled.reshape(-1, 119, 1)\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Reshaped Train:\", X_train_cnn.shape)\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de42fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.293186Z",
     "iopub.status.busy": "2025-11-15T10:51:09.291799Z",
     "iopub.status.idle": "2025-11-15T10:51:09.477748Z",
     "shell.execute_reply": "2025-11-15T10:51:09.476693Z"
    },
    "papermill": {
     "duration": 0.197022,
     "end_time": "2025-11-15T10:51:09.479366",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.282344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-11-15 10:51:09.311600: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">117</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m117\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m2,322\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,530</span> (627.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,530\u001b[0m (627.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,634</span> (623.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m159,634\u001b[0m (623.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = 18   # detected from your data\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(119, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    layers.Conv1D(256, kernel_size=3, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalMaxPooling1D(),\n",
    "\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a5b29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.498999Z",
     "iopub.status.busy": "2025-11-15T10:51:09.498286Z",
     "iopub.status.idle": "2025-11-15T10:51:09.502525Z",
     "shell.execute_reply": "2025-11-15T10:51:09.501673Z"
    },
    "papermill": {
     "duration": 0.015592,
     "end_time": "2025-11-15T10:51:09.504245",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.488653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b53610e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:51:09.523220Z",
     "iopub.status.busy": "2025-11-15T10:51:09.522635Z",
     "iopub.status.idle": "2025-11-15T10:54:41.707394Z",
     "shell.execute_reply": "2025-11-15T10:54:41.706217Z"
    },
    "papermill": {
     "duration": 212.197128,
     "end_time": "2025-11-15T10:54:41.709717",
     "exception": false,
     "start_time": "2025-11-15T10:51:09.512589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.1138 - loss: 3.7086 - val_accuracy: 0.1215 - val_loss: 2.7374\n",
      "Epoch 2/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.2704 - loss: 2.2606 - val_accuracy: 0.1796 - val_loss: 2.5772\n",
      "Epoch 3/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.3432 - loss: 1.9646 - val_accuracy: 0.2667 - val_loss: 2.3204\n",
      "Epoch 4/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4022 - loss: 1.7375 - val_accuracy: 0.3538 - val_loss: 1.9830\n",
      "Epoch 5/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.4451 - loss: 1.5908 - val_accuracy: 0.4266 - val_loss: 1.6822\n",
      "Epoch 6/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4824 - loss: 1.4686 - val_accuracy: 0.4703 - val_loss: 1.5390\n",
      "Epoch 7/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.5257 - loss: 1.3449 - val_accuracy: 0.4798 - val_loss: 1.4919\n",
      "Epoch 8/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.5464 - loss: 1.2646 - val_accuracy: 0.5022 - val_loss: 1.4135\n",
      "Epoch 9/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.5740 - loss: 1.2012 - val_accuracy: 0.4928 - val_loss: 1.4449\n",
      "Epoch 10/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.6051 - loss: 1.0940 - val_accuracy: 0.5198 - val_loss: 1.3911\n",
      "Epoch 11/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.6310 - loss: 1.0085 - val_accuracy: 0.5215 - val_loss: 1.3604\n",
      "Epoch 12/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.6422 - loss: 0.9567 - val_accuracy: 0.5247 - val_loss: 1.4009\n",
      "Epoch 13/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6352 - loss: 0.9565 - val_accuracy: 0.5174 - val_loss: 1.3751\n",
      "Epoch 14/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.6801 - loss: 0.8670 - val_accuracy: 0.5427 - val_loss: 1.2892\n",
      "Epoch 15/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.6979 - loss: 0.8209 - val_accuracy: 0.5284 - val_loss: 1.3519\n",
      "Epoch 16/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7215 - loss: 0.7442 - val_accuracy: 0.5460 - val_loss: 1.3656\n",
      "Epoch 17/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7201 - loss: 0.7346 - val_accuracy: 0.5337 - val_loss: 1.3367\n",
      "Epoch 18/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7365 - loss: 0.6754 - val_accuracy: 0.5505 - val_loss: 1.3425\n",
      "Epoch 19/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7588 - loss: 0.6340 - val_accuracy: 0.5505 - val_loss: 1.3298\n",
      "Epoch 20/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.7490 - loss: 0.6614 - val_accuracy: 0.5505 - val_loss: 1.3667\n",
      "Epoch 21/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.7756 - loss: 0.5716 - val_accuracy: 0.5497 - val_loss: 1.3963\n",
      "Epoch 22/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.7815 - loss: 0.5601 - val_accuracy: 0.5407 - val_loss: 1.4375\n",
      "Epoch 23/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7967 - loss: 0.5384 - val_accuracy: 0.5607 - val_loss: 1.3614\n",
      "Epoch 24/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8007 - loss: 0.5158 - val_accuracy: 0.5493 - val_loss: 1.4153\n",
      "Epoch 25/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8317 - loss: 0.4571 - val_accuracy: 0.5607 - val_loss: 1.5311\n",
      "Epoch 26/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.8305 - loss: 0.4416 - val_accuracy: 0.5599 - val_loss: 1.5238\n",
      "Epoch 27/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.8476 - loss: 0.4136 - val_accuracy: 0.5460 - val_loss: 1.6336\n",
      "Epoch 28/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8493 - loss: 0.3993 - val_accuracy: 0.5423 - val_loss: 1.8128\n",
      "Epoch 29/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8544 - loss: 0.3922 - val_accuracy: 0.5558 - val_loss: 1.5908\n",
      "Epoch 30/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8616 - loss: 0.3757 - val_accuracy: 0.5403 - val_loss: 1.7249\n",
      "Epoch 31/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8337 - loss: 0.4414 - val_accuracy: 0.5366 - val_loss: 1.7549\n",
      "Epoch 32/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8368 - loss: 0.4159 - val_accuracy: 0.5558 - val_loss: 1.6196\n",
      "Epoch 33/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8684 - loss: 0.3509 - val_accuracy: 0.5399 - val_loss: 1.6828\n",
      "Epoch 34/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8355 - loss: 0.4601 - val_accuracy: 0.5534 - val_loss: 1.7080\n",
      "Epoch 35/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8814 - loss: 0.3232 - val_accuracy: 0.5476 - val_loss: 1.6887\n",
      "Epoch 36/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8906 - loss: 0.3045 - val_accuracy: 0.5497 - val_loss: 1.8567\n",
      "Epoch 37/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.8719 - loss: 0.3375 - val_accuracy: 0.5509 - val_loss: 1.8607\n",
      "Epoch 38/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9000 - loss: 0.2715 - val_accuracy: 0.5640 - val_loss: 1.8413\n",
      "Epoch 39/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.8989 - loss: 0.2841 - val_accuracy: 0.5370 - val_loss: 2.0401\n",
      "Epoch 40/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.8903 - loss: 0.2976 - val_accuracy: 0.5505 - val_loss: 1.8537\n",
      "Epoch 41/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.8918 - loss: 0.2955 - val_accuracy: 0.5550 - val_loss: 1.8538\n",
      "Epoch 42/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9108 - loss: 0.2505 - val_accuracy: 0.5640 - val_loss: 1.9024\n",
      "Epoch 43/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9149 - loss: 0.2388 - val_accuracy: 0.5493 - val_loss: 2.0999\n",
      "Epoch 44/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9122 - loss: 0.2406 - val_accuracy: 0.5603 - val_loss: 2.0238\n",
      "Epoch 45/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9234 - loss: 0.2030 - val_accuracy: 0.5575 - val_loss: 1.9356\n",
      "Epoch 46/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9290 - loss: 0.2046 - val_accuracy: 0.5530 - val_loss: 2.1642\n",
      "Epoch 47/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9132 - loss: 0.2386 - val_accuracy: 0.5636 - val_loss: 2.0807\n",
      "Epoch 48/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9076 - loss: 0.2555 - val_accuracy: 0.5566 - val_loss: 2.0263\n",
      "Epoch 49/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9269 - loss: 0.2110 - val_accuracy: 0.5546 - val_loss: 2.1822\n",
      "Epoch 50/50\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.9290 - loss: 0.2111 - val_accuracy: 0.5550 - val_loss: 2.1309\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa875c4d",
   "metadata": {
    "papermill": {
     "duration": 0.130215,
     "end_time": "2025-11-15T10:54:41.970948",
     "exception": false,
     "start_time": "2025-11-15T10:54:41.840733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43fde460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:54:42.235185Z",
     "iopub.status.busy": "2025-11-15T10:54:42.234826Z",
     "iopub.status.idle": "2025-11-15T10:54:43.240809Z",
     "shell.execute_reply": "2025-11-15T10:54:43.239444Z"
    },
    "papermill": {
     "duration": 1.144322,
     "end_time": "2025-11-15T10:54:43.242721",
     "exception": false,
     "start_time": "2025-11-15T10:54:42.098399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Validation Accuracy: 0.5550102249488753\n",
      "Validation Macro F1: 0.5687377856456846\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = np.argmax(model.predict(X_val_cnn), axis=1)\n",
    "\n",
    "val_acc = (y_val_pred == y_val).mean()\n",
    "val_f1  = f1_score(y_val, y_val_pred, average='macro')\n",
    "\n",
    "print(\"Validation Accuracy:\", val_acc)\n",
    "print(\"Validation Macro F1:\", val_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4934cf99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:54:43.503418Z",
     "iopub.status.busy": "2025-11-15T10:54:43.502750Z",
     "iopub.status.idle": "2025-11-15T10:54:43.661874Z",
     "shell.execute_reply": "2025-11-15T10:54:43.660791Z"
    },
    "papermill": {
     "duration": 0.289237,
     "end_time": "2025-11-15T10:54:43.663460",
     "exception": false,
     "start_time": "2025-11-15T10:54:43.374223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">118</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,322</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m118\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m393,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m2,322\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">645,330</span> (2.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m645,330\u001b[0m (2.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">643,922</span> (2.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m643,922\u001b[0m (2.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To improve the val_acc and val_f1, adding more dropouts\n",
    "model1 = Sequential([\n",
    "    # Block 1\n",
    "    Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(119, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    # Block 2\n",
    "    Conv1D(filters=128, kernel_size=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    # Block 3\n",
    "    Conv1D(filters=256, kernel_size=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    # Block 4 (new)\n",
    "    Conv1D(filters=256, kernel_size=2, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    # Dense Layer 1 (more capacity)\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Dense Layer 2 (new)\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Dense(18, activation='softmax')\n",
    "])\n",
    "\n",
    "# Lower learning rate for better generalization\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model1.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50a7bf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:54:43.920529Z",
     "iopub.status.busy": "2025-11-15T10:54:43.919709Z",
     "iopub.status.idle": "2025-11-15T10:54:43.927133Z",
     "shell.execute_reply": "2025-11-15T10:54:43.926066Z"
    },
    "papermill": {
     "duration": 0.138526,
     "end_time": "2025-11-15T10:54:43.928859",
     "exception": false,
     "start_time": "2025-11-15T10:54:43.790333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f75571cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T10:54:44.195336Z",
     "iopub.status.busy": "2025-11-15T10:54:44.194999Z",
     "iopub.status.idle": "2025-11-15T11:00:16.336731Z",
     "shell.execute_reply": "2025-11-15T11:00:16.335394Z"
    },
    "papermill": {
     "duration": 332.281904,
     "end_time": "2025-11-15T11:00:16.338643",
     "exception": false,
     "start_time": "2025-11-15T10:54:44.056739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 67ms/step - accuracy: 0.1363 - loss: 3.1710 - val_accuracy: 0.1771 - val_loss: 2.7465\n",
      "Epoch 2/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.3066 - loss: 2.0281 - val_accuracy: 0.1779 - val_loss: 2.4689\n",
      "Epoch 3/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.3865 - loss: 1.6973 - val_accuracy: 0.3076 - val_loss: 2.0641\n",
      "Epoch 4/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.4316 - loss: 1.4741 - val_accuracy: 0.4438 - val_loss: 1.6113\n",
      "Epoch 5/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.4688 - loss: 1.3495 - val_accuracy: 0.5027 - val_loss: 1.4254\n",
      "Epoch 6/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.5267 - loss: 1.1994 - val_accuracy: 0.5382 - val_loss: 1.2820\n",
      "Epoch 7/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.5682 - loss: 1.0888 - val_accuracy: 0.5358 - val_loss: 1.2670\n",
      "Epoch 8/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.5684 - loss: 1.0533 - val_accuracy: 0.5624 - val_loss: 1.1997\n",
      "Epoch 9/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.5873 - loss: 1.0004 - val_accuracy: 0.5808 - val_loss: 1.1302\n",
      "Epoch 10/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.6146 - loss: 0.9002 - val_accuracy: 0.5624 - val_loss: 1.1668\n",
      "Epoch 11/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6503 - loss: 0.7758 - val_accuracy: 0.5881 - val_loss: 1.1261\n",
      "Epoch 12/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.6751 - loss: 0.7325 - val_accuracy: 0.6012 - val_loss: 1.1130\n",
      "Epoch 13/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.6966 - loss: 0.6910 - val_accuracy: 0.6049 - val_loss: 1.0789\n",
      "Epoch 14/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7179 - loss: 0.6496 - val_accuracy: 0.6033 - val_loss: 1.1078\n",
      "Epoch 15/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7415 - loss: 0.5602 - val_accuracy: 0.5935 - val_loss: 1.0960\n",
      "Epoch 16/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7371 - loss: 0.6046 - val_accuracy: 0.6110 - val_loss: 1.0871\n",
      "Epoch 17/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7574 - loss: 0.5254 - val_accuracy: 0.6188 - val_loss: 1.0606\n",
      "Epoch 18/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7916 - loss: 0.4353 - val_accuracy: 0.6192 - val_loss: 1.1593\n",
      "Epoch 19/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8011 - loss: 0.4045 - val_accuracy: 0.6241 - val_loss: 1.1334\n",
      "Epoch 20/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8143 - loss: 0.3825 - val_accuracy: 0.6045 - val_loss: 1.1873\n",
      "Epoch 21/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8178 - loss: 0.3822 - val_accuracy: 0.6139 - val_loss: 1.1825\n",
      "Epoch 22/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8385 - loss: 0.3340 - val_accuracy: 0.6192 - val_loss: 1.2093\n",
      "Epoch 23/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8342 - loss: 0.3469 - val_accuracy: 0.6151 - val_loss: 1.2114\n",
      "Epoch 24/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8549 - loss: 0.2924 - val_accuracy: 0.6147 - val_loss: 1.2757\n",
      "Epoch 25/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8711 - loss: 0.2702 - val_accuracy: 0.6127 - val_loss: 1.2970\n",
      "Epoch 26/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8641 - loss: 0.2759 - val_accuracy: 0.6123 - val_loss: 1.3075\n",
      "Epoch 27/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.8884 - loss: 0.2375 - val_accuracy: 0.6294 - val_loss: 1.3256\n",
      "Epoch 28/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8916 - loss: 0.2455 - val_accuracy: 0.6270 - val_loss: 1.3873\n",
      "Epoch 29/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.8922 - loss: 0.2121 - val_accuracy: 0.6294 - val_loss: 1.3488\n",
      "Epoch 30/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9007 - loss: 0.2089 - val_accuracy: 0.6286 - val_loss: 1.3534\n",
      "Epoch 31/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9243 - loss: 0.1635 - val_accuracy: 0.6294 - val_loss: 1.4380\n",
      "Epoch 32/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9174 - loss: 0.1897 - val_accuracy: 0.6245 - val_loss: 1.4229\n",
      "Epoch 33/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.9192 - loss: 0.1680 - val_accuracy: 0.6335 - val_loss: 1.4392\n",
      "Epoch 34/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9303 - loss: 0.1582 - val_accuracy: 0.6254 - val_loss: 1.4611\n",
      "Epoch 35/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9316 - loss: 0.1525 - val_accuracy: 0.6217 - val_loss: 1.5552\n",
      "Epoch 36/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9329 - loss: 0.1365 - val_accuracy: 0.6221 - val_loss: 1.5037\n",
      "Epoch 37/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9352 - loss: 0.1511 - val_accuracy: 0.6274 - val_loss: 1.5224\n",
      "Epoch 38/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9363 - loss: 0.1573 - val_accuracy: 0.6188 - val_loss: 1.4966\n",
      "Epoch 39/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.9377 - loss: 0.1436 - val_accuracy: 0.6204 - val_loss: 1.6624\n",
      "Epoch 40/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9364 - loss: 0.1592 - val_accuracy: 0.6176 - val_loss: 1.6575\n",
      "Epoch 41/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9285 - loss: 0.1853 - val_accuracy: 0.6221 - val_loss: 1.6381\n",
      "Epoch 42/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9426 - loss: 0.1344 - val_accuracy: 0.6282 - val_loss: 1.6109\n",
      "Epoch 43/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9476 - loss: 0.1221 - val_accuracy: 0.6233 - val_loss: 1.5969\n",
      "Epoch 44/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.9442 - loss: 0.1311 - val_accuracy: 0.6290 - val_loss: 1.7179\n",
      "Epoch 45/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9530 - loss: 0.1296 - val_accuracy: 0.6233 - val_loss: 1.7278\n",
      "Epoch 46/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9622 - loss: 0.0854 - val_accuracy: 0.6327 - val_loss: 1.7651\n",
      "Epoch 47/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9514 - loss: 0.1109 - val_accuracy: 0.6057 - val_loss: 1.9437\n",
      "Epoch 48/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9369 - loss: 0.1612 - val_accuracy: 0.6098 - val_loss: 1.6892\n",
      "Epoch 49/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9519 - loss: 0.1142 - val_accuracy: 0.6221 - val_loss: 1.6937\n",
      "Epoch 50/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.9573 - loss: 0.1075 - val_accuracy: 0.6115 - val_loss: 1.7797\n",
      "Epoch 51/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9653 - loss: 0.0887 - val_accuracy: 0.6274 - val_loss: 1.7743\n",
      "Epoch 52/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9244 - loss: 0.2317 - val_accuracy: 0.6143 - val_loss: 1.6212\n",
      "Epoch 53/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9382 - loss: 0.1278 - val_accuracy: 0.6241 - val_loss: 1.7771\n",
      "Epoch 54/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9491 - loss: 0.1451 - val_accuracy: 0.6290 - val_loss: 1.7271\n",
      "Epoch 55/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9647 - loss: 0.0959 - val_accuracy: 0.6323 - val_loss: 1.7420\n",
      "Epoch 56/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9596 - loss: 0.0813 - val_accuracy: 0.6429 - val_loss: 1.8110\n",
      "Epoch 57/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9703 - loss: 0.0716 - val_accuracy: 0.6384 - val_loss: 1.8619\n",
      "Epoch 58/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - accuracy: 0.9685 - loss: 0.0818 - val_accuracy: 0.6401 - val_loss: 1.7703\n",
      "Epoch 59/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.9640 - loss: 0.0880 - val_accuracy: 0.6413 - val_loss: 1.8350\n",
      "Epoch 60/60\n",
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.9708 - loss: 0.0822 - val_accuracy: 0.6344 - val_loss: 1.8805\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(\n",
    "    X_train_cnn,\n",
    "    y_train,\n",
    "    validation_data=(X_val_cnn, y_val),\n",
    "    epochs=60,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb657960",
   "metadata": {
    "papermill": {
     "duration": 0.412126,
     "end_time": "2025-11-15T11:00:17.171460",
     "exception": false,
     "start_time": "2025-11-15T11:00:16.759334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24a896e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:18.133742Z",
     "iopub.status.busy": "2025-11-15T11:00:18.132575Z",
     "iopub.status.idle": "2025-11-15T11:00:19.356976Z",
     "shell.execute_reply": "2025-11-15T11:00:19.355726Z"
    },
    "papermill": {
     "duration": 1.640307,
     "end_time": "2025-11-15T11:00:19.358700",
     "exception": false,
     "start_time": "2025-11-15T11:00:17.718393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "Validation Accuracy: 0.6343558282208589\n",
      "Validation Macro F1: 0.645763211839946\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = np.argmax(model1.predict(X_val_cnn), axis=1)\n",
    "\n",
    "val_acc = (y_val_pred == y_val).mean()\n",
    "val_f1  = f1_score(y_val, y_val_pred, average='macro')\n",
    "\n",
    "print(\"Validation Accuracy:\", val_acc)\n",
    "print(\"Validation Macro F1:\", val_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7649116f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:20.168408Z",
     "iopub.status.busy": "2025-11-15T11:00:20.167856Z",
     "iopub.status.idle": "2025-11-15T11:00:20.296328Z",
     "shell.execute_reply": "2025-11-15T11:00:20.294776Z"
    },
    "papermill": {
     "duration": 0.536172,
     "end_time": "2025-11-15T11:00:20.298850",
     "exception": false,
     "start_time": "2025-11-15T11:00:19.762678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>gesture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>Write name in air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>Above ear - pull hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id                gesture\n",
       "0  SEQ_000001      Write name in air\n",
       "1  SEQ_000011  Above ear - pull hair"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare test data\n",
    "X_test = df_test_features.drop(columns=['sequence_id', 'subject'])\n",
    "\n",
    "X_test_cnn = X_test.values.reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "# Predictions\n",
    "test_preds = np.argmax(model.predict(X_test_cnn), axis=1)\n",
    "\n",
    "# Convert back to original gesture labels\n",
    "test_gestures = le.inverse_transform(test_preds)\n",
    "\n",
    "# Build submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    \"sequence_id\": df_test_features[\"sequence_id\"],\n",
    "    \"gesture\": test_gestures\n",
    "})\n",
    "\n",
    "# submission.to_csv(\"submission_1dcnn.csv\", index=False)\n",
    "\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d48d1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:21.161735Z",
     "iopub.status.busy": "2025-11-15T11:00:21.160796Z",
     "iopub.status.idle": "2025-11-15T11:00:21.265079Z",
     "shell.execute_reply": "2025-11-15T11:00:21.263643Z"
    },
    "papermill": {
     "duration": 0.552974,
     "end_time": "2025-11-15T11:00:21.266988",
     "exception": false,
     "start_time": "2025-11-15T11:00:20.714014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "  sequence_id      predicted_gesture\n",
      "0  SEQ_000011  Above ear - pull hair\n",
      "1  SEQ_000001      Write name in air\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test_features.drop(columns=['sequence_id', 'subject'])\n",
    "\n",
    "# Reshape for CNN\n",
    "X_test_cnn = X_test.values.astype('float32').reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "# Random 10\n",
    "n_samples = min(10, len(X_test))\n",
    "random_indices = np.random.choice(len(X_test), size=n_samples, replace=False)\n",
    "\n",
    "X_sample_cnn = X_test_cnn[random_indices]\n",
    "\n",
    "# Predict\n",
    "sample_preds = np.argmax(model.predict(X_sample_cnn), axis=1)\n",
    "sample_gestures = le.inverse_transform(sample_preds)\n",
    "\n",
    "# Results\n",
    "results = pd.DataFrame({\n",
    "    \"sequence_id\": df_test_features.iloc[random_indices][\"sequence_id\"].values,\n",
    "    \"predicted_gesture\": sample_gestures\n",
    "})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f2c57c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:22.218438Z",
     "iopub.status.busy": "2025-11-15T11:00:22.217933Z",
     "iopub.status.idle": "2025-11-15T11:00:28.059160Z",
     "shell.execute_reply": "2025-11-15T11:00:28.058037Z"
    },
    "papermill": {
     "duration": 6.25817,
     "end_time": "2025-11-15T11:00:28.061351",
     "exception": false,
     "start_time": "2025-11-15T11:00:21.803181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e47642f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:28.917007Z",
     "iopub.status.busy": "2025-11-15T11:00:28.916621Z",
     "iopub.status.idle": "2025-11-15T11:00:28.933481Z",
     "shell.execute_reply": "2025-11-15T11:00:28.932459Z"
    },
    "papermill": {
     "duration": 0.432878,
     "end_time": "2025-11-15T11:00:28.935575",
     "exception": false,
     "start_time": "2025-11-15T11:00:28.502697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "OPTIMIZER_NAME = \"AdamW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ab98723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:29.787572Z",
     "iopub.status.busy": "2025-11-15T11:00:29.786733Z",
     "iopub.status.idle": "2025-11-15T11:00:29.814963Z",
     "shell.execute_reply": "2025-11-15T11:00:29.813753Z"
    },
    "papermill": {
     "duration": 0.438192,
     "end_time": "2025-11-15T11:00:29.816757",
     "exception": false,
     "start_time": "2025-11-15T11:00:29.378565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Giả lập dữ liệu (bạn thay bằng dữ liệu thực nếu có)\n",
    "N, T, H, W, C = 100, 10, 8, 8, 3   # 100 mẫu, 10 khung, 8x8, 3 kênh\n",
    "X = np.random.rand(N, T, H, W, C).astype(np.float32)\n",
    "y = np.random.randint(0, 2, size=(N,))  # ví dụ 2 lớp (nhị phân)\n",
    "\n",
    "# Chia train/val\n",
    "X_train, X_val = X[:80], X[80:]\n",
    "y_train, y_val = y[:80], y[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fc42752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:30.778802Z",
     "iopub.status.busy": "2025-11-15T11:00:30.777288Z",
     "iopub.status.idle": "2025-11-15T11:00:30.806223Z",
     "shell.execute_reply": "2025-11-15T11:00:30.805209Z"
    },
    "papermill": {
     "duration": 0.453833,
     "end_time": "2025-11-15T11:00:30.808145",
     "exception": false,
     "start_time": "2025-11-15T11:00:30.354312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GraphConv(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(in_dim, out_dim, bias=False)\n",
    "    def forward(self, X, A):\n",
    "        return torch.matmul(A, self.lin(X))\n",
    "\n",
    "class SimpleGCN(torch.nn.Module):\n",
    "    def __init__(self, H, W, in_ch, nclass):\n",
    "        super().__init__()\n",
    "        self.N = H * W\n",
    "        self.gc1 = GraphConv(in_ch, 32)\n",
    "        self.gc2 = GraphConv(32, 64)\n",
    "        self.fc = torch.nn.Linear(64, nclass)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        # x: (B, T, H, W, C)\n",
    "        B, T, H, W, C = x.shape\n",
    "        x = x.reshape(B, T, H * W, C)\n",
    "        outs = []\n",
    "        for t in range(T):\n",
    "            h = F.relu(self.gc1(x[:, t], A))\n",
    "            h = F.relu(self.gc2(h, A))\n",
    "            pooled = h.mean(1)\n",
    "            outs.append(pooled)\n",
    "        out = torch.stack(outs, 1).mean(1)\n",
    "        return self.fc(out)\n",
    "\n",
    "class SimpleGAT(torch.nn.Module):\n",
    "    def __init__(self, H, W, in_ch, nclass, heads=4):\n",
    "        super().__init__()\n",
    "        self.N = H * W\n",
    "        self.fc1 = torch.nn.Linear(in_ch, 32)\n",
    "        self.attn = torch.nn.MultiheadAttention(32, num_heads=heads, batch_first=True)\n",
    "        self.fc2 = torch.nn.Linear(32, nclass)\n",
    "\n",
    "    def forward(self, x, A=None):  # A không dùng, nhưng giữ để tương thích\n",
    "        B, T, H, W, C = x.shape\n",
    "        x = x.reshape(B, T, H * W, C)\n",
    "        outs = []\n",
    "        for t in range(T):\n",
    "            h = F.relu(self.fc1(x[:, t]))\n",
    "            attn_out, _ = self.attn(h, h, h)\n",
    "            pooled = attn_out.mean(1)\n",
    "            outs.append(pooled)\n",
    "        out = torch.stack(outs, 1).mean(1)\n",
    "        return self.fc2(out)\n",
    "\n",
    "class CNN2D(torch.nn.Module):\n",
    "    def __init__(self, nclass, in_ch):\n",
    "        super().__init__()\n",
    "        self.frame = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_ch, 32, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(32, 64, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.temporal = torch.nn.LSTM(64, 64, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(64, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, H, W, C)\n",
    "        B, T, H, W, C = x.shape\n",
    "        feats = []\n",
    "        for t in range(T):\n",
    "            xt = x[:, t].permute(0, 3, 1, 2)  # -> (B, C, H, W)\n",
    "            feat = self.frame(xt).flatten(1)\n",
    "            feats.append(feat)\n",
    "        z = torch.stack(feats, 1)\n",
    "        z, _ = self.temporal(z)\n",
    "        z = z.mean(1)\n",
    "        return self.fc(z)\n",
    "\n",
    "class CNN3D(torch.nn.Module):\n",
    "    def __init__(self, nclass, in_ch):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_ch, 16, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool3d((2,2,2)),\n",
    "            torch.nn.Conv3d(16, 32, 3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AdaptiveAvgPool3d(1)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(32, nclass)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, H, W, C)\n",
    "        x = x.permute(0, 4, 1, 2, 3)  # -> (B, C, T, H, W)\n",
    "        z = self.net(x).flatten(1)\n",
    "        return self.fc(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6dad967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:31.654372Z",
     "iopub.status.busy": "2025-11-15T11:00:31.653822Z",
     "iopub.status.idle": "2025-11-15T11:00:31.673607Z",
     "shell.execute_reply": "2025-11-15T11:00:31.672324Z"
    },
    "papermill": {
     "duration": 0.423209,
     "end_time": "2025-11-15T11:00:31.675481",
     "exception": false,
     "start_time": "2025-11-15T11:00:31.252272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_val_reshaped = X_val.reshape(-1, X_val.shape[-1])\n",
    "\n",
    "scaler = StandardScaler().fit(X_train_reshaped)\n",
    "X_train = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val_reshaped).reshape(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef6f929f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:32.482630Z",
     "iopub.status.busy": "2025-11-15T11:00:32.482310Z",
     "iopub.status.idle": "2025-11-15T11:00:32.503260Z",
     "shell.execute_reply": "2025-11-15T11:00:32.501993Z"
    },
    "papermill": {
     "duration": 0.427307,
     "end_time": "2025-11-15T11:00:32.505065",
     "exception": false,
     "start_time": "2025-11-15T11:00:32.077758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_experiments(X_train, y_train, X_val, y_val, H=8, W=8, mask_channel=None, epochs=80):\n",
    "    import torch, torch.nn as nn, torch.nn.functional as F, numpy as np, time, pandas as pd\n",
    "    from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    in_channels = X_train.shape[-1]\n",
    "\n",
    "    # === Helper: adjacency 8-neighbor ===\n",
    "    def build_adjacency(H, W):\n",
    "        A = torch.zeros(H*W, H*W)\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                idx = i * W + j\n",
    "                for di in [-1, 0, 1]:\n",
    "                    for dj in [-1, 0, 1]:\n",
    "                        ni, nj = i+di, j+dj\n",
    "                        if 0 <= ni < H and 0 <= nj < W:\n",
    "                            n_idx = ni * W + nj\n",
    "                            A[idx, n_idx] = 1\n",
    "        D_inv = torch.diag(1.0 / (A.sum(1) + 1e-5))\n",
    "        return (D_inv @ A).to(DEVICE)\n",
    "\n",
    "    A_hat = build_adjacency(H, W)\n",
    "\n",
    "    # === DataLoader ===\n",
    "    bs = 32\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                       torch.tensor(y_train, dtype=torch.long)),\n",
    "        batch_size=bs, shuffle=True)\n",
    "    dl_va = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                       torch.tensor(y_val, dtype=torch.long)),\n",
    "        batch_size=bs, shuffle=False)\n",
    "\n",
    "    # === Models ===\n",
    "    models = {\n",
    "        \"GCN\": lambda: SimpleGCN(H, W, in_ch=in_channels, nclass=n_classes),\n",
    "        \"GAT\": lambda: SimpleGAT(H, W, in_ch=in_channels, nclass=n_classes),\n",
    "        \"CNN2D\": lambda: CNN2D(nclass=n_classes, in_ch=in_channels),\n",
    "        \"CNN3D\": lambda: CNN3D(nclass=n_classes, in_ch=in_channels),\n",
    "    }\n",
    "\n",
    "    # === Evaluate ===\n",
    "    @torch.no_grad()\n",
    "    def evaluate(model, dl, A=None):\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for xb, yb in dl:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb, A) if A is not None else model(xb)\n",
    "            y_pred += logits.argmax(1).cpu().tolist()\n",
    "            y_true += yb.cpu().tolist()\n",
    "        macro = f1_score(y_true, y_pred, average='macro')\n",
    "        binary = f1_score(y_true, y_pred, average='binary') if len(set(y_true)) == 2 else 0\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        return binary, macro, acc\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # === Train each model ===\n",
    "    for name, fn in models.items():\n",
    "        print(f\"\\n▶ Training {name} ...\")\n",
    "        model = fn().to(DEVICE)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "        params_m = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "\n",
    "        best_macro = 0\n",
    "        patience = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(1, epochs+1):\n",
    "            model.train()\n",
    "            for xb, yb in dl_tr:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                opt.zero_grad()\n",
    "                logits = model(xb, A_hat) if name in [\"GCN\", \"GAT\"] else model(xb)\n",
    "                loss = F.cross_entropy(logits, yb)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            bin_f1, mac_f1, acc = evaluate(model, dl_va, A_hat if name in [\"GCN\",\"GAT\"] else None)\n",
    "            if ep % 5 == 0:\n",
    "                print(f\"Epoch {ep}/{epochs}: loss={loss.item():.3f}, Macro={mac_f1:.3f}, Acc={acc:.3f}\")\n",
    "            if mac_f1 > best_macro:\n",
    "                best_macro = mac_f1\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience > 10:\n",
    "                    print(f\"⏹ Early stop at epoch {ep}\")\n",
    "                    break\n",
    "\n",
    "        train_time = time.time() - start\n",
    "        start_inf = time.time()\n",
    "        evaluate(model, dl_va, A_hat if name in [\"GCN\",\"GAT\"] else None)\n",
    "        inf_time = (time.time() - start_inf) / len(dl_va.dataset)\n",
    "\n",
    "        bin_f1, mac_f1, acc = evaluate(model, dl_va, A_hat if name in [\"GCN\",\"GAT\"] else None)\n",
    "        results.append({\n",
    "            \"features_used\": \"ToF_Grid\",\n",
    "            \"window_size\": 10,\n",
    "            \"optimizer/solver\": \"AdamW+Cosine\",\n",
    "            \"params (M)\": round(params_m, 4),\n",
    "            \"Binary\": round(bin_f1, 4),\n",
    "            \"Macro\": round(mac_f1, 4),\n",
    "            \"Final Score\": round(mac_f1/2, 4),\n",
    "            \"val_acc\": round(acc, 4),\n",
    "            \"train_time\": round(train_time, 2),\n",
    "            \"inference_time\": round(inf_time, 4),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"\\n=== RESULTS ===\")\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf6b3fa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T11:00:33.484554Z",
     "iopub.status.busy": "2025-11-15T11:00:33.483554Z",
     "iopub.status.idle": "2025-11-15T11:00:46.381995Z",
     "shell.execute_reply": "2025-11-15T11:00:46.380745Z"
    },
    "papermill": {
     "duration": 13.310535,
     "end_time": "2025-11-15T11:00:46.383870",
     "exception": false,
     "start_time": "2025-11-15T11:00:33.073335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Training GCN ...\n",
      "Epoch 5/80: loss=0.693, Macro=0.375, Acc=0.600\n",
      "Epoch 10/80: loss=0.694, Macro=0.286, Acc=0.400\n",
      "Epoch 15/80: loss=0.698, Macro=0.286, Acc=0.400\n",
      "⏹ Early stop at epoch 19\n",
      "\n",
      "▶ Training GAT ...\n",
      "Epoch 5/80: loss=0.684, Macro=0.286, Acc=0.400\n",
      "Epoch 10/80: loss=0.661, Macro=0.286, Acc=0.400\n",
      "⏹ Early stop at epoch 12\n",
      "\n",
      "▶ Training CNN2D ...\n",
      "Epoch 5/80: loss=0.703, Macro=0.286, Acc=0.400\n",
      "Epoch 10/80: loss=0.687, Macro=0.286, Acc=0.400\n",
      "⏹ Early stop at epoch 12\n",
      "\n",
      "▶ Training CNN3D ...\n",
      "Epoch 5/80: loss=0.718, Macro=0.286, Acc=0.400\n",
      "Epoch 10/80: loss=0.703, Macro=0.286, Acc=0.400\n",
      "⏹ Early stop at epoch 12\n",
      "\n",
      "=== RESULTS ===\n",
      "  features_used  window_size optimizer/solver  params (M)  Binary   Macro  \\\n",
      "0      ToF_Grid           10     AdamW+Cosine      0.0023  0.5714  0.2857   \n",
      "1      ToF_Grid           10     AdamW+Cosine      0.0044  0.5714  0.2857   \n",
      "2      ToF_Grid           10     AdamW+Cosine      0.0528  0.5714  0.2857   \n",
      "3      ToF_Grid           10     AdamW+Cosine      0.0152  0.5714  0.2857   \n",
      "\n",
      "   Final Score  val_acc  train_time  inference_time  \n",
      "0       0.1429      0.4        1.34          0.0005  \n",
      "1       0.1429      0.4        2.20          0.0010  \n",
      "2       0.1429      0.4        1.46          0.0007  \n",
      "3       0.1429      0.4        0.48          0.0004  \n",
      "✅ Submission file saved successfully at: /kaggle/working/submission.parquet\n"
     ]
    }
   ],
   "source": [
    "report = run_experiments(X_train, y_train, X_val, y_val, H=8, W=8, epochs=80)\n",
    "\n",
    "# Define output path\n",
    "output_path = \"/kaggle/working/submission.parquet\"\n",
    "\n",
    "# Save the submission file in the correct format and location\n",
    "report.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Submission file saved successfully at: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4181.079464,
   "end_time": "2025-11-15T11:00:49.516444",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T09:51:08.436980",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
